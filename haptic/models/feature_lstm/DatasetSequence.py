"""
æ—¶åºç­–ç•¥å­¦ä¹ æ•°æ®é›† - åŸºäºPointPairDatasetæ‰©å±•
æ”¯æŒLSTMè®­ç»ƒæ‰€éœ€çš„æ—¶åºæ•°æ®åŠ è½½
"""
import os
import torch
import numpy as np
import random
import hashlib
import json
from torch.utils.data import Dataset
from DatasetPointPair import PointPairDataset

class SequenceDataset(PointPairDataset):
    """
    æ—¶åºç­–ç•¥å­¦ä¹ æ•°æ®é›†ï¼Œæ‰©å±•è‡ªPointPairDataset
    æ”¯æŒåŠ è½½è¿ç»­æ—¶åºæ•°æ®ç”¨äºLSTMè®­ç»ƒ
    """
    
    def __init__(self, data_root, categories=None, is_train=True, use_resultant=True, use_forces=False,
                 normalization_config=None, sequence_length=10, prediction_step=1, overlap_stride=5):
        """
        Args:
            data_root: æ•°æ®æ ¹ç›®å½•è·¯å¾„
            categories: è¦åŒ…å«çš„ç±»åˆ«åˆ—è¡¨
            is_train: æ˜¯å¦åŠ è½½è®­ç»ƒé›†æ•°æ®
            use_resultant: æ˜¯å¦ä½¿ç”¨resultantæ•°æ®
            use_forces: æ˜¯å¦ä½¿ç”¨forcesæ•°æ®
            normalization_config: å½’ä¸€åŒ–é…ç½®å­—å…¸
            sequence_length: æ—¶åºåºåˆ—é•¿åº¦ (LSTMè¾“å…¥çš„æ—¶é—´æ­¥æ•°)
            prediction_step: é¢„æµ‹æ­¥é•¿ï¼Œé¢„æµ‹åºåˆ—åç¬¬prediction_stepä¸ªæ—¶åˆ»çš„åŠ¨ä½œ
            overlap_stride: åºåˆ—é‡å æ­¥é•¿ï¼Œæ§åˆ¶æ»‘åŠ¨çª—å£çš„æ­¥é•¿
        """
        self.sequence_length = sequence_length
        self.overlap_stride = overlap_stride
        
        # è°ƒç”¨çˆ¶ç±»åˆå§‹åŒ–ï¼Œä½†ä½¿ç”¨prediction_step=1ï¼ˆå› ä¸ºæˆ‘ä»¬ä¼šé‡æ–°æ„å»ºç´¢å¼•ï¼‰
        super().__init__(
            data_root=data_root, 
            categories=categories, 
            is_train=is_train,
            use_resultant=use_resultant,
            use_forces=use_forces,
            normalization_config=normalization_config,
            prediction_step=prediction_step
        )
        
        # é‡æ–°æ„å»ºæ—¶åºç´¢å¼•
        self._build_sequence_indices()
        
    def _build_sequence_indices(self):
        """æ„å»ºæ—¶åºåºåˆ—ç´¢å¼• - ä½¿ç”¨prediction_stepä½œä¸ºå…¨å±€é‡‡æ ·é—´éš”"""
        self.sequence_indices = []
        
        for traj_idx, traj_info in enumerate(self.trajectories):
            # è¯»å–æœ«ç«¯ä½ç½®æ•°æ®ç¡®å®šé•¿åº¦
            position_data = np.load(os.path.join(traj_info['path'], "_end_position.npy"))
            trajectory_length = len(position_data)
            
            # æ–°é‡‡æ ·ç­–ç•¥ï¼šä½¿ç”¨prediction_stepä½œä¸ºå…¨å±€é‡‡æ ·é—´éš”T
            # åºåˆ—é‡‡æ ·ä½ç½®: [start, start+T, start+2T, ..., start+(sequence_length-1)*T]
            # é¢„æµ‹ç›®æ ‡ä½ç½®: start + sequence_length * T
            # æ‰€ä»¥æœ€å°è½¨è¿¹é•¿åº¦éœ€è¦: start + sequence_length * prediction_step
            min_required_length = self.sequence_length * self.prediction_step + 1
            
            if trajectory_length < min_required_length:
                continue  # è·³è¿‡å¤ªçŸ­çš„è½¨è¿¹
            
            # æ»‘åŠ¨çª—å£ç”Ÿæˆåºåˆ—
            # åºåˆ—èµ·å§‹ä½ç½®çš„èŒƒå›´: [0, trajectory_length - min_required_length]
            max_start_idx = trajectory_length - min_required_length
            
            for start_idx in range(0, max_start_idx + 1, self.overlap_stride):
                # è®¡ç®—åºåˆ—ä¸­æ¯ä¸ªæ—¶é—´æ­¥çš„å®é™…ç´¢å¼•
                seq_indices = [start_idx + i * self.prediction_step for i in range(self.sequence_length)]
                target_idx = start_idx + self.sequence_length * self.prediction_step  # é¢„æµ‹ç›®æ ‡ä½ç½®
                
                self.sequence_indices.append({
                    'traj_idx': traj_idx,
                    'seq_indices': seq_indices,      # åºåˆ—ä¸­æ¯ä¸ªæ—¶é—´æ­¥çš„å®é™…ç´¢å¼•
                    'target_idx': target_idx,        # ç›®æ ‡åŠ¨ä½œç´¢å¼•
                    'seq_length': self.sequence_length,  # åºåˆ—é•¿åº¦
                    'sampling_interval': self.prediction_step  # é‡‡æ ·é—´éš”
                })
        
        # æ‰“ä¹±åºåˆ—ç´¢å¼•
        random.seed(self.random_seed)
        random.shuffle(self.sequence_indices)
        
        print(f"æ—¶åºæ¨¡å¼ (åºåˆ—é•¿åº¦={self.sequence_length}, é‡‡æ ·é—´éš”={self.prediction_step}, é‡å æ­¥é•¿={self.overlap_stride}): {len(self.sequence_indices)} åºåˆ—å·²åŠ è½½ã€‚")
        
    def _print_dataset_info(self):
        """æ‰“å°æ•°æ®é›†ä¿¡æ¯"""
        total_trajectories = len(self.trajectories)
        total_sequences = len(getattr(self, 'sequence_indices', []))
        
        print(f"[SequenceDataset] æ•°æ®ç»Ÿè®¡:")
        print(f"  - è½¨è¿¹æ•°é‡: {total_trajectories}")
        print(f"  - åºåˆ—æ•°é‡: {total_sequences}")
        print(f"  - åºåˆ—é•¿åº¦: {self.sequence_length}")
        print(f"  - é‡‡æ ·é—´éš”: {self.prediction_step}")
        print(f"  - é‡å æ­¥é•¿: {self.overlap_stride}")
        print(f"  - å½“å‰é›†åˆ: {'è®­ç»ƒé›†' if self.is_train else 'æµ‹è¯•é›†'}")

    def __len__(self):
        return len(self.sequence_indices)

    def __getitem__(self, idx):
        """è·å–æ—¶åºåºåˆ—æ ·æœ¬"""
        sequence_info = self.sequence_indices[idx]
        traj_info = self.trajectories[sequence_info['traj_idx']]
        traj_path = traj_info['path']
        
        seq_indices = sequence_info['seq_indices']  # åºåˆ—ä¸­æ¯ä¸ªæ—¶é—´æ­¥çš„å®é™…ç´¢å¼•
        target_idx = sequence_info['target_idx']
        
        return self._load_sequence_data(traj_path, traj_info, seq_indices, target_idx)

    def _load_sequence_data(self, traj_path, traj_info, seq_indices, target_idx):
        """
        åŠ è½½æ—¶åºåºåˆ—æ•°æ® - ä½¿ç”¨é—´éš”é‡‡æ ·ï¼Œæ”¯æŒå¯†é›†ç›‘ç£
        Args:
            seq_indices: åºåˆ—ä¸­æ¯ä¸ªæ—¶é—´æ­¥çš„å®é™…ç´¢å¼•åˆ—è¡¨ [start, start+T, start+2T, ...]
            target_idx: ç›®æ ‡åŠ¨ä½œç´¢å¼•
        Returns:
            result: åŒ…å«æ—¶åºè¾“å…¥æ•°æ®å’Œç›®æ ‡åŠ¨ä½œçš„å­—å…¸
        """
        # åŠ è½½æœ«ç«¯ä½ç½®æ•°æ®
        position_data = np.load(os.path.join(traj_path, "_end_position.npy"))
        
        # åºåˆ—åŠ¨ä½œæ•°æ® (å†å²åŠ¨ä½œåºåˆ—) - æŒ‰é—´éš”é‡‡æ ·
        action_seq = []
        for idx in seq_indices:
            action = position_data[idx, 1:4]  # (3,) XYZåæ ‡
            action_seq.append(self._normalize_data(action, 'actions'))
        action_seq = np.array(action_seq)  # (seq_len, 3)
        
        # ç›®æ ‡åŠ¨ä½œ (é¢„æµ‹ç›®æ ‡) - å•æ­¥é¢„æµ‹
        target_action = position_data[target_idx, 1:4]  # (3,) XYZåæ ‡
        target_action = self._normalize_data(target_action, 'actions')
        
        # å¯†é›†ç›‘ç£çš„ç›®æ ‡åŠ¨ä½œåºåˆ— - æ‰€æœ‰æ—¶é—´æ­¥çš„ç›®æ ‡åŠ¨ä½œ
        # æ„å»ºç›®æ ‡åºåˆ—ï¼šä»seq_indices[0]+prediction_stepå¼€å§‹çš„è¿ç»­åŠ¨ä½œ
        target_action_seq = []
        start_target_idx = seq_indices[0] + self.prediction_step
        for i in range(len(seq_indices)):
            target_seq_idx = start_target_idx + i * self.prediction_step
            if target_seq_idx < len(position_data):
                target_action_seq.append(self._normalize_data(position_data[target_seq_idx, 1:4], 'actions'))
            else:
                # å¦‚æœè¶…å‡ºèŒƒå›´ï¼Œä½¿ç”¨æœ€åä¸€ä¸ªæœ‰æ•ˆåŠ¨ä½œ
                target_action_seq.append(self._normalize_data(position_data[-1, 1:4], 'actions'))
        target_action_seq = np.array(target_action_seq)  # (seq_len, 3)
        
        result = {
            'action_seq': torch.FloatTensor(action_seq),          # (seq_len, 3) å†å²åŠ¨ä½œåºåˆ—
            'target_next_action': torch.FloatTensor(target_action),  # (3,) ç›®æ ‡åŠ¨ä½œï¼ˆå•æ­¥ï¼‰
            'target_action_seq': torch.FloatTensor(target_action_seq),  # (seq_len, 3) ç›®æ ‡åŠ¨ä½œåºåˆ—ï¼ˆå¯†é›†ç›‘ç£ï¼‰
            'category': traj_info['category'],
            'trajectory_id': traj_info['dir_name'],
            'seq_indices': seq_indices,  # åºåˆ—å®é™…ç´¢å¼•
            'target_idx': target_idx,
            'seq_length': len(seq_indices),
            'sampling_interval': self.prediction_step
        }
        
        # åŠ è½½æ—¶åºè§¦è§‰æ•°æ®
        if self.use_resultant:
            # åŠ è½½resultantsæ—¶åºæ•°æ®
            resultant_force_l_data = np.load(os.path.join(traj_path, "_resultant_force_l.npy"))
            resultant_force_r_data = np.load(os.path.join(traj_path, "_resultant_force_r.npy"))
            resultant_moment_l_data = np.load(os.path.join(traj_path, "_resultant_moment_l.npy"))
            resultant_moment_r_data = np.load(os.path.join(traj_path, "_resultant_moment_r.npy"))
            
            # æå–åºåˆ— - æŒ‰é—´éš”é‡‡æ ·
            resultant_force_l_seq = []
            resultant_force_r_seq = []
            resultant_moment_l_seq = []
            resultant_moment_r_seq = []
            
            for idx in seq_indices:
                resultant_force_l_seq.append(self._normalize_data(resultant_force_l_data[idx], 'resultants'))
                resultant_force_r_seq.append(self._normalize_data(resultant_force_r_data[idx], 'resultants'))
                resultant_moment_l_seq.append(self._normalize_data(resultant_moment_l_data[idx], 'resultants'))
                resultant_moment_r_seq.append(self._normalize_data(resultant_moment_r_data[idx], 'resultants'))
            
            # è½¬æ¢ä¸ºnumpyæ•°ç»„åå†åˆ›å»ºtensor (æ€§èƒ½ä¼˜åŒ–)
            result['resultant_force_l_seq'] = torch.FloatTensor(np.array(resultant_force_l_seq))    # (seq_len, 3)
            result['resultant_force_r_seq'] = torch.FloatTensor(np.array(resultant_force_r_seq))    # (seq_len, 3)
            result['resultant_moment_l_seq'] = torch.FloatTensor(np.array(resultant_moment_l_seq))  # (seq_len, 3)
            result['resultant_moment_r_seq'] = torch.FloatTensor(np.array(resultant_moment_r_seq))  # (seq_len, 3)
        
        if self.use_forces:
            # åŠ è½½forcesæ—¶åºæ•°æ®
            forces_l_data = np.load(os.path.join(traj_path, "_forces_l.npy"))
            forces_r_data = np.load(os.path.join(traj_path, "_forces_r.npy"))
            
            # æå–åºåˆ—å¹¶å½’ä¸€åŒ– - æŒ‰é—´éš”é‡‡æ ·
            forces_l_seq = []
            forces_r_seq = []
            
            for idx in seq_indices:
                forces_l_seq.append(self._normalize_data(forces_l_data[idx], 'forces'))
                forces_r_seq.append(self._normalize_data(forces_r_data[idx], 'forces'))
            
            # è½¬æ¢ä¸ºnumpyæ•°ç»„åå†åˆ›å»ºtensor (æ€§èƒ½ä¼˜åŒ–)
            result['forces_l_seq'] = torch.FloatTensor(np.array(forces_l_seq))  # (seq_len, 3, 20, 20)
            result['forces_r_seq'] = torch.FloatTensor(np.array(forces_r_seq))  # (seq_len, 3, 20, 20)
        
        return result


def create_sequence_datasets(data_root, categories=None, normalization_config=None, 
                           sequence_length=10, prediction_step=1, overlap_stride=5,
                           use_forces=True):
    """
    åˆ›å»ºæ—¶åºè®­ç»ƒé›†å’Œæµ‹è¯•é›†
    Args:
        sequence_length: æ—¶åºåºåˆ—é•¿åº¦
        prediction_step: é¢„æµ‹æ­¥é•¿
        overlap_stride: åºåˆ—é‡å æ­¥é•¿
        use_forces: æ˜¯å¦ä½¿ç”¨forcesæ•°æ®ï¼ˆLSTMé€šå¸¸éœ€è¦å®Œæ•´çš„è§¦è§‰æ•°æ®ï¼‰
    """
    # 1. å…ˆåˆ›å»ºè®­ç»ƒé›†
    train_dataset = SequenceDataset(
        data_root=data_root,
        categories=categories,
        is_train=True,
        use_forces=use_forces,  # LSTMé€šå¸¸ä½¿ç”¨å®Œæ•´çš„è§¦è§‰æ•°æ®
        use_resultant=False,     # ä¹Ÿå¯ä»¥ä½¿ç”¨resultantæ•°æ®
        normalization_config=normalization_config,
        sequence_length=sequence_length,
        prediction_step=prediction_step,
        overlap_stride=overlap_stride
    )
    
    # 2. åˆ›å»ºæµ‹è¯•é›†ï¼Œä½¿ç”¨è®­ç»ƒé›†çš„å½’ä¸€åŒ–å‚æ•°
    test_dataset = SequenceDataset(
        data_root=data_root,
        categories=categories,
        is_train=False,
        use_forces=use_forces,
        use_resultant=False,
        normalization_config=train_dataset.normalization_config,
        sequence_length=sequence_length,
        prediction_step=prediction_step,
        overlap_stride=overlap_stride
    )
    
    print(f"ğŸ“Š æ—¶åºæ•°æ®é›†ä¿¡æ¯:")
    action_params = train_dataset.normalization_config.get('actions', {})
    forces_params = train_dataset.normalization_config.get('forces', {})
    print(f"   Actionså½’ä¸€åŒ–: {action_params.get('method', 'None')}")
    print(f"   Forceså½’ä¸€åŒ–: {forces_params.get('method', 'None')}")
    print(f"   æµ‹è¯•é›†ä½¿ç”¨é¢„è®¡ç®—å‚æ•°: {test_dataset.use_precomputed_normalization}")
    
    return train_dataset, test_dataset, train_dataset.get_normalization_params()


# è‡ªå®šä¹‰collateå‡½æ•°å¤„ç†å˜é•¿åºåˆ—ï¼ˆå¯é€‰ï¼‰
def sequence_collate_fn(batch):
    """
    è‡ªå®šä¹‰collateå‡½æ•°ï¼Œæ”¯æŒå˜é•¿åºåˆ—ï¼ˆå¦‚æœéœ€è¦çš„è¯ï¼‰
    ç›®å‰å‡è®¾æ‰€æœ‰åºåˆ—é•¿åº¦ç›¸åŒï¼Œå¯ä»¥æ‰©å±•æ”¯æŒå˜é•¿
    """
    # å½“å‰å®ç°ï¼šå‡è®¾æ‰€æœ‰åºåˆ—é•¿åº¦ç›¸åŒ
    return torch.utils.data.dataloader.default_collate(batch)


if __name__ == '__main__':
    # æµ‹è¯•æ—¶åºæ•°æ®é›†
    print("ğŸ§ª æµ‹è¯•æ—¶åºæ•°æ®é›†...")
    
    train_dataset, test_dataset, norm_config = create_sequence_datasets(
        data_root='data25.7_aligned',
        categories=['cir_lar'],  # æµ‹è¯•ç”¨å°æ•°æ®é›†
        sequence_length=8,
        prediction_step=1,
        overlap_stride=4,
        use_forces=True
    )
    
    print(f"\nğŸ“Š æ•°æ®é›†å¤§å°:")
    print(f"  è®­ç»ƒé›†: {len(train_dataset)} åºåˆ—")
    print(f"  æµ‹è¯•é›†: {len(test_dataset)} åºåˆ—")
    
    # æµ‹è¯•æ•°æ®åŠ è½½
    sample = train_dataset[0]
    print(f"\nğŸ“¦ æ ·æœ¬æ•°æ®ç»“æ„:")
    for key, value in sample.items():
        if isinstance(value, torch.Tensor):
            print(f"  {key}: {value.shape}")
        else:
            print(f"  {key}: {value}")
    
    # æµ‹è¯•DataLoader
    from torch.utils.data import DataLoader
    loader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=sequence_collate_fn)
    
    batch = next(iter(loader))
    print(f"\nğŸ“¦ æ‰¹æ¬¡æ•°æ®ç»“æ„:")
    for key, value in batch.items():
        if isinstance(value, torch.Tensor):
            print(f"  {key}: {value.shape}")
        else:
            print(f"  {key}: {type(value)} (é•¿åº¦: {len(value)})")
    
    print("âœ… æ—¶åºæ•°æ®é›†æµ‹è¯•å®Œæˆï¼")
