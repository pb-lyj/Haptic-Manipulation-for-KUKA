"""
Feature-LSTMç­–ç•¥æ¨¡å‹è®­ç»ƒè„šæœ¬ - æ—¶åºç‰ˆæœ¬
è¾“å…¥: æ—¶åºè§¦è§‰æ•°æ® forces_l[seq_len, 3, 20, 20] + forces_r[seq_len, 3, 20, 20] + action_seq[seq_len, 3]
è¾“å‡º: action_nextstep[3]
"""
import os
import sys
import torch
import wandb
import numpy as np
from torch.utils.data import DataLoader
from tqdm import tqdm
from datetime import datetime

# è®¾ç½®ä»£ç†ï¼ˆå¦‚æœéœ€è¦ä»£ç†æ‰èƒ½è®¿é—®å¤–ç½‘ï¼‰
os.environ["HTTP_PROXY"] = "http://127.0.0.1:7897"
os.environ["HTTPS_PROXY"] = "http://127.0.0.1:7897"
os.environ["WANDB_HTTP_TIMEOUT"] = "60"

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.abspath(os.path.dirname(__file__)))

# é¡¹ç›®æ ¹è·¯å¾„
project_root = os.path.abspath(os.path.dirname(__file__))

from DatasetSequence import create_sequence_datasets
from feature_lstm import create_tactile_policy_feature_lstm, compute_feature_lstm_losses, prepare_feature_lstm_input_from_sequence_dataset


def train_feature_lstm_policy(config):
    """
    è®­ç»ƒFeature-LSTMç­–ç•¥æ¨¡å‹
    """
    print("ğŸš€ å¼€å§‹Feature-LSTMç­–ç•¥è®­ç»ƒ...")
    
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_dir = os.path.join(config['output']['output_dir'], f"feature_lstm_policy_{timestamp}")
    os.makedirs(output_dir, exist_ok=True)
    
    # åˆå§‹åŒ– wandb
    run = wandb.init(
        project=config.get('wandb', {}).get('project', 'tactile-action-learn'),
        name=config.get('wandb', {}).get('name'),
        config=config,
        dir=output_dir,
        tags=['feature-lstm-policy', 'sequence-prediction'] + [timestamp],
        notes='Feature-LSTM policy training with sequential tactile data'
    )
    
    # è®¾ç½®è®¾å¤‡
    torch.cuda.set_device(1)
    device = torch.device('cuda:1')
    # device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ğŸ“± ä½¿ç”¨è®¾å¤‡: {device}")
    
    print("=" * 60)
    print("Feature-LSTM Policy Training")
    print(f"Output Directory: {output_dir}")
    print(f"Data Root: {config['data']['data_root']}")
    print(f"Batch Size: {config['training']['batch_size']}")
    print(f"Epochs: {config['training']['epochs']}")
    print(f"Learning Rate: {config['training']['lr']}")
    print(f"Sequence Length: {config['data']['sequence_length']}")
    print(f"Sampling Interval: {config['data']['sampling_interval']}")
    print("=" * 60)
    print("Model Configuration:")
    print(config['model'])
    print("=" * 60)
    
    # åˆ›å»ºæ—¶åºæ•°æ®é›†
    print("ğŸ“‚ åŠ è½½æ—¶åºæ•°æ®é›†...")
    train_dataset, test_dataset, normalization_params = create_sequence_datasets(
        data_root=config['data']['data_root'],
        categories=config['data']['categories'],
        sequence_length=config['data']['sequence_length'],
        prediction_step=config['data']['sampling_interval'],
        overlap_stride=config['data'].get('overlap_stride', 5),
        use_forces=True,  # Feature-LSTMéœ€è¦è§¦è§‰æ•°æ®
        normalization_config=config['data'].get('normalization_config', None)
    )
    
    # å°†è®¡ç®—å‡ºçš„å½’ä¸€åŒ–å‚æ•°æ›´æ–°åˆ°configä¸­
    if normalization_params:
        # æ›´æ–°configä¸­çš„normalization_configä¸ºè®¡ç®—å‡ºçš„å®é™…å‚æ•°
        config['data']['normalization_config'] = normalization_params
        print("ğŸ“Š å½’ä¸€åŒ–å‚æ•°å·²æ›´æ–°åˆ°configä¸­")
        
        # æ‰“å°å‚æ•°ä¿¡æ¯
        for data_type, params in normalization_params.items():
            if 'params' in params and params['params']:
                print(f"   {data_type}: {params['method']}")
                if data_type == 'actions' and isinstance(params['params'], dict):
                    # é€è½´å‚æ•°
                    if any(key.startswith('axis_') for key in params['params'].keys()):
                        for axis_name, axis_params in params['params'].items():
                            if isinstance(axis_params, dict):
                                print(f"     {axis_name}: mean={axis_params.get('mean', 'N/A'):.4f}, std={axis_params.get('std', 'N/A'):.4f}")
                    else:
                        # å…¨å±€å‚æ•°
                        print(f"     global: mean={params['params'].get('mean', 'N/A'):.4f}, std={params['params'].get('std', 'N/A'):.4f}")
                else:
                    # å…¶ä»–æ•°æ®ç±»å‹çš„å…¨å±€å‚æ•°
                    print(f"     mean={params['params'].get('mean', 'N/A'):.4f}, std={params['params'].get('std', 'N/A'):.4f}")
        
        # ç›´æ¥æ›´æ–°WandBçš„configï¼Œè¿™æ ·ä¼šå†™å…¥åˆ°config.yamlæ–‡ä»¶ä¸­
        print("ğŸ“ æ­£åœ¨å°†å½’ä¸€åŒ–å‚æ•°å†™å…¥WandB config.yamlæ–‡ä»¶...")
        
        # æ–¹æ³•1ï¼šæ›´æ–°å®Œæ•´çš„configç»“æ„åˆ°WandBï¼ˆå…è®¸å€¼å˜æ›´ï¼‰
        wandb.config.update(config, allow_val_change=True)
        
        # æ–¹æ³•2ï¼šå•ç‹¬æ›´æ–°å½’ä¸€åŒ–å‚æ•°ï¼ˆç¡®ä¿è¢«è®°å½•ï¼‰
        wandb.config.update({
            'computed_normalization_params': normalization_params,
            'normalization_computed_at_runtime': True
        }, allow_val_change=True)
        
        print("âœ… å½’ä¸€åŒ–å‚æ•°å·²å†™å…¥WandB config.yamlæ–‡ä»¶")
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    train_loader = DataLoader(
        train_dataset, 
        batch_size=config['training']['batch_size'], 
        shuffle=True, 
        num_workers=4, 
        pin_memory=True if device.type == 'cuda' else False
    )
    
    test_loader = DataLoader(
        test_dataset, 
        batch_size=config['training']['batch_size'], 
        shuffle=False, 
        num_workers=4, 
        pin_memory=True if device.type == 'cuda' else False
    )

    print(f"âœ… è®­ç»ƒé›†: {len(train_dataset)} åºåˆ—")
    print(f"âœ… æµ‹è¯•é›†: {len(test_dataset)} åºåˆ—")

    # åˆ›å»ºæ¨¡å‹
    print("ğŸ—ï¸ åˆ›å»ºFeature-LSTMæ¨¡å‹...")
    model = create_tactile_policy_feature_lstm(config['model']).to(device)
    print(f"æ¨¡å‹å‚æ•°æ•°é‡: {sum(p.numel() for p in model.parameters()):,}")
    print(f"å¯è®­ç»ƒå‚æ•°æ•°é‡: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}")
    
    # ä¼˜åŒ–å™¨å’Œè°ƒåº¦å™¨
    optimizer = torch.optim.AdamW(
        model.parameters(), 
        lr=config['training']['lr'], 
        weight_decay=config['training']['weight_decay']
    )
    
    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
        optimizer, mode='min', factor=0.5, patience=10
    )

    # è®­ç»ƒå¾ªç¯
    best_loss = float('inf')
    best_model_path = None
    
    # å¯†é›†ç›‘ç£é…ç½®
    dense_supervision = config['training'].get('dense_supervision', False)
    print(f"ğŸ¯ ç›‘ç£æ¨¡å¼: {'å¯†é›†ç›‘ç£ (æ¯æ—¶é—´æ­¥)' if dense_supervision else 'ç¨€ç–ç›‘ç£ (æœ€åä¸€æ­¥)'}")
    
    try:
        for epoch in range(config['training']['epochs']):
            print(f"\nğŸ”„ Epoch {epoch + 1}/{config['training']['epochs']}")
            
            # è®­ç»ƒé˜¶æ®µ
            train_loss, train_metrics = train_epoch(model, train_loader, optimizer, device, train_dataset, dense_supervision=dense_supervision, current_epoch=epoch+1, total_epochs=config['training']['epochs'])
            
            print(f"ğŸ“ˆ è®­ç»ƒç»“æœ:")
            print(f"   Loss: {train_loss:.6f}")
            print(f"   L1 error: {train_metrics.get('l1_error', 0):.6f}")
            print(f"   mse error: {train_metrics.get('mse_error', 0):.6f}")
            print(f"   direction_loss: {train_metrics.get('direction_loss', 0):.6f}")
            print(f"   magnitude_loss: {train_metrics.get('magnitude_loss', 0):.6f}")
            print(f"   diversity_loss: {train_metrics.get('diversity_loss', 0):.6f}")
            print(f"   diversity_weight: {train_metrics.get('diversity_weight', 0):.6f}")
            print(f"   step_norm_penalty: {train_metrics.get('step_norm_penalty', 0):.6f}")
            print(f"   avg_step_norm: {train_metrics.get('avg_step_norm', 0):.6f}")
            print(f"   Real L1 Error: {train_metrics.get('real_l1_error(mm)', 0):.2f} mm")
            print(f"   Real L1 Max: {train_metrics.get('real_l1_error_max(mm)', 0):.2f} mm")
            
            # è®°å½•è®­ç»ƒæŒ‡æ ‡åˆ° wandb
            train_wandb_log = {'learning_rate': optimizer.param_groups[0]['lr']}
            for key, value in train_metrics.items():
                train_wandb_log[f'train/{key}'] = value
            
            run.log(train_wandb_log, step=epoch)

            # éªŒè¯é˜¶æ®µ
            if (epoch + 1) % config['training'].get('eval_every', 1) == 0:
                test_loss, test_metrics = evaluate(model, test_loader, device, test_dataset, dense_supervision=dense_supervision, current_epoch=epoch+1, total_epochs=config['training']['epochs'])
                
                print(f"ğŸ“Š éªŒè¯ç»“æœ:")
                print(f"   Loss: {test_loss:.6f}")
                print(f"   l1_error: {test_metrics.get('l1_error', 0):.6f}")
                print(f"   mse_error: {test_metrics.get('mse_error', 0):.6f}")
                print(f"   direction_loss: {test_metrics.get('direction_loss', 0):.6f}")
                print(f"   magnitude_loss: {test_metrics.get('magnitude_loss', 0):.6f}")
                print(f"   diversity_loss: {test_metrics.get('diversity_loss', 0):.6f}")
                print(f"   diversity_weight: {test_metrics.get('diversity_weight', 0):.6f}")
                print(f"   step_norm_penalty: {test_metrics.get('step_norm_penalty', 0):.6f}")
                print(f"   avg_step_norm: {test_metrics.get('avg_step_norm', 0):.6f}")
                print(f"   Real L1 Error: {test_metrics.get('real_l1_error(mm)', 0):.2f} mm")
                print(f"   Real L1 Max: {test_metrics.get('real_l1_error_max(mm)', 0):.2f} mm")

                
                # è®°å½•éªŒè¯æŒ‡æ ‡åˆ° wandb
                val_wandb_log = {}
                for key, value in test_metrics.items():
                    val_wandb_log[f'val/{key}'] = value
                
                run.log(val_wandb_log, step=epoch)
                
                # ä¿å­˜æœ€ä½³æ¨¡å‹
                if test_loss < best_loss:
                    best_loss = test_loss
                    best_model_path = os.path.join(output_dir, "best_model.pt")
                    torch.save({
                        'model_state_dict': model.state_dict(),
                        'optimizer_state_dict': optimizer.state_dict(),
                        'epoch': epoch,
                        'train_loss': train_loss,
                        'test_loss': test_loss,
                        'config': config,
                        'normalization_params': normalization_params
                    }, best_model_path)
                    print(f"ğŸ’¾ ä¿å­˜æœ€ä½³æ¨¡å‹: {best_model_path}")
                
                # å­¦ä¹ ç‡è°ƒåº¦
                scheduler.step(test_loss)
            
            # å®šæœŸä¿å­˜æ£€æŸ¥ç‚¹
            if (epoch + 1) % config['training'].get('save_every', 20) == 0:
                checkpoint_path = os.path.join(output_dir, f"checkpoint_epoch_{epoch+1}.pt")
                torch.save({
                    'model_state_dict': model.state_dict(),
                    'optimizer_state_dict': optimizer.state_dict(),
                    'epoch': epoch,
                    'train_loss': train_loss,
                    'test_loss': test_loss if 'test_loss' in locals() else None,
                    'config': config,
                    'normalization_params': normalization_params
                }, checkpoint_path)
                print(f"ğŸ’¾ ä¿å­˜æ£€æŸ¥ç‚¹: {checkpoint_path}")
        
        # ä¿å­˜æœ€ç»ˆæ¨¡å‹
        final_model_path = os.path.join(output_dir, "final_model.pt")
        torch.save({
            'model_state_dict': model.state_dict(),
            'optimizer_state_dict': optimizer.state_dict(),
            'epoch': epoch,
            'train_loss': train_loss,
            'test_loss': test_loss if 'test_loss' in locals() else None,
            'config': config,
            'normalization_params': normalization_params
        }, final_model_path)
        
        # ä¿å­˜åˆ° wandb
        wandb.save(final_model_path)
        if best_model_path:
            wandb.save(best_model_path)
        
        print("âœ… Feature-LSTMç­–ç•¥æ¨¡å‹è®­ç»ƒå®Œæˆ!")
        print(f"ğŸ“ˆ æœ€ä½³éªŒè¯æŸå¤±: {best_loss:.6f}")
        
        return model, best_loss, best_model_path
        
    except Exception as e:
        print(f"âŒ è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        raise
    finally:
        run.finish()


def train_epoch(model, train_loader, optimizer, device, dataset=None, dense_supervision=False, current_epoch=1, total_epochs=10):
    """è®­ç»ƒä¸€ä¸ªepoch - é€‚é…ç®€å•ç‰ˆæœ¬çš„feature_lstm"""
    model.train()
    total_loss = 0.0
    total_metrics = {}
    total_samples = 0
    
    for batch_idx, batch in enumerate(tqdm(train_loader, desc="Training")):
        # å‡†å¤‡è¾“å…¥æ•°æ®
        lstm_inputs = prepare_feature_lstm_input_from_sequence_dataset(batch, dense_supervision=dense_supervision)
        for key in lstm_inputs:
            if isinstance(lstm_inputs[key], torch.Tensor):
                lstm_inputs[key] = lstm_inputs[key].to(device)
        
        # å‰å‘ä¼ æ’­
        optimizer.zero_grad()
        forces_l = lstm_inputs['forces_l']  # (B, T, 3, 20, 20)
        forces_r = lstm_inputs['forces_r']  # (B, T, 3, 20, 20)
        actions = lstm_inputs['actions']    # (B, T, 3)
        seq_lengths = lstm_inputs.get('seq_lengths', None)  # (B,) å¯é€‰
        
        # æ ¹æ®æ˜¯å¦ä½¿ç”¨å¯†é›†ç›‘ç£å†³å®šæ¨¡å‹è¾“å‡º
        outputs = model(forces_l, forces_r, actions, seq_lengths, return_all_steps=dense_supervision)
        
        # è®¡ç®—æŸå¤±ï¼ˆä½¿ç”¨ç®€å•ç‰ˆæœ¬çš„æŸå¤±å‡½æ•°ï¼‰
        loss, metrics = compute_feature_lstm_losses(
            lstm_inputs, outputs, dataset=dataset, 
            dense_supervision=dense_supervision,
            current_epoch=current_epoch,
            total_epochs=total_epochs
        )
        
        # åå‘ä¼ æ’­
        loss.backward()
        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
        optimizer.step()
        
        # ç´¯ç§¯ç»Ÿè®¡
        batch_size = forces_l.size(0)
        total_loss += loss.item() * batch_size
        total_samples += batch_size
        
        # ç´¯ç§¯æŒ‡æ ‡
        for key, value in metrics.items():
            if isinstance(value, (int, float)):
                if key not in total_metrics:
                    total_metrics[key] = 0
                total_metrics[key] += value * batch_size
    
    avg_loss = total_loss / max(total_samples, 1)
    avg_metrics = {key: value / max(total_samples, 1) 
                   for key, value in total_metrics.items()}
    
    return avg_loss, avg_metrics


def evaluate(model, test_loader, device, dataset=None, dense_supervision=False, current_epoch=1, total_epochs=10):
    """è¯„ä¼°æ¨¡å‹ - æ”¯æŒå¯†é›†ç›‘ç£"""
    model.eval()
    total_loss = 0.0
    total_metrics = {}
    total_samples = 0
    
    with torch.no_grad():
        for batch in tqdm(test_loader, desc="Evaluating"):
            # å‡†å¤‡è¾“å…¥æ•°æ®
            lstm_inputs = prepare_feature_lstm_input_from_sequence_dataset(batch, dense_supervision=dense_supervision)
            for key in lstm_inputs:
                if isinstance(lstm_inputs[key], torch.Tensor):
                    lstm_inputs[key] = lstm_inputs[key].to(device)
            
            # å‰å‘ä¼ æ’­
            forces_l = lstm_inputs['forces_l']  # (B, T, 3, 20, 20)
            forces_r = lstm_inputs['forces_r']  # (B, T, 3, 20, 20)
            actions = lstm_inputs['actions']    # (B, T, 3)
            seq_lengths = lstm_inputs.get('seq_lengths', None)  # (B,) å¯é€‰
            
            # æ ¹æ®æ˜¯å¦ä½¿ç”¨å¯†é›†ç›‘ç£å†³å®šæ¨¡å‹è¾“å‡º
            outputs = model(forces_l, forces_r, actions, seq_lengths, return_all_steps=dense_supervision)
            
            # è®¡ç®—æŸå¤±ï¼ˆä½¿ç”¨ç®€å•ç‰ˆæœ¬çš„æŸå¤±å‡½æ•°ï¼‰
            loss, metrics = compute_feature_lstm_losses(
                lstm_inputs, outputs, dataset=dataset, 
                dense_supervision=dense_supervision,
                current_epoch=current_epoch,
                total_epochs=total_epochs
            )
            
            # ç´¯åŠ ç»Ÿè®¡
            batch_size = forces_l.size(0)
            total_loss += loss.item() * batch_size
            total_samples += batch_size
            
            # ç´¯åŠ æŒ‡æ ‡
            for key, value in metrics.items():
                if isinstance(value, (int, float)):
                    if key not in total_metrics:
                        total_metrics[key] = 0.0
                    total_metrics[key] += value * batch_size
    
    avg_loss = total_loss / max(total_samples, 1)
    avg_metrics = {key: value / max(total_samples, 1) 
                   for key, value in total_metrics.items()}
    
    return avg_loss, avg_metrics


def main(config):
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ Feature-LSTMç­–ç•¥è®­ç»ƒå¼€å§‹")
    print(f"ğŸ“Š é…ç½®æ‘˜è¦:")
    print(f"  - åºåˆ—é•¿åº¦: {config['data']['sequence_length']}")
    print(f"  - é‡‡æ ·é—´éš”: {config['data']['sampling_interval']}")
    print(f"  - æ‰¹æ¬¡å¤§å°: {config['training']['batch_size']}")
    print(f"  - è®­ç»ƒè½®æ•°: {config['training']['epochs']}")
    print(f"  - å­¦ä¹ ç‡: {config['training']['lr']}")
    
    train_feature_lstm_policy(config)


if __name__ == '__main__':
    # é»˜è®¤é…ç½®
    config = {
        'data': {
            'data_root': 'data25.7_aligned',
            'categories': [
                "cir_lar", "cir_med", "cir_sma",
                "rect_lar", "rect_med", "rect_sma", 
                "tri_lar", "tri_med", "tri_sma",
            ],
            'sequence_length': 10,      # LSTMè¾“å…¥åºåˆ—é•¿åº¦
            'sampling_interval': 5,    # é‡‡æ ·é—´éš”T: [0, T, 2T, 3T, 4T] -> 5T
            'overlap_stride': 1,       # åºåˆ—é‡å æ­¥é•¿
            'normalization_config': {
                'actions': {'method': 'zscore', 'params': None, 'axis_mode': 'global'},
                'forces': {'method': 'zscore', 'params': None}
            }
        },
        'model': {
            'feature_dim': 128,              # CNNç‰¹å¾ç»´åº¦
            'action_dim': 3,                 # è¾“å‡ºåŠ¨ä½œç»´åº¦
            'lstm_hidden_dim': 256,          # LSTMéšè—ç»´åº¦
            'lstm_num_layers': 2,            # LSTMå±‚æ•°
            'dropout_rate': 0.2,             # Dropoutæ¯”ç‡
            'pretrained_encoder_path': 'cnnae_crt_128.pt',  # é¢„è®­ç»ƒCNNç¼–ç å™¨è·¯å¾„
            'action_embed_dim': 64,          # åŠ¨ä½œåµŒå…¥ç»´åº¦
            'fc_hidden_dims': [256, 128, 64] # å…¨è¿æ¥å±‚ç»´åº¦
        },
        'training': {
            'batch_size': 24,        # æ—¶åºæ•°æ®è¾ƒå¤§ï¼Œä½¿ç”¨è¾ƒå°æ‰¹æ¬¡
            'epochs': 15,           
            'lr': 5e-4,              # è¾ƒå°å­¦ä¹ ç‡ç”¨äºå¾®è°ƒ
            'weight_decay': 1e-5,
            'eval_every': 1,         # æ¯ eval_every è½®éªŒè¯
            'save_every': 10,        # æ¯ save_every è½®ä¿å­˜ä¸€æ¬¡æ£€æŸ¥ç‚¹
            'dense_supervision': True,  # å¯ç”¨å¯†é›†ç›‘ç£ (æ¯ä¸ªæ—¶é—´æ­¥éƒ½ç›‘ç£)
        },
        'wandb': {
            'project': "tactile-action-learn-test",
            'name': 'feature-lstm-delta_policy-AIDO-Div0.1decay0-LargeStep',  # absolute input delta output
        },
        'output': {
            'output_dir': 'checkpoints'
        }
    }
    
    # æ£€æŸ¥è·¯å¾„
    data_path = os.path.join(project_root, config['data']['data_root'])
    config['data']['data_root'] = data_path
    config['output']['output_dir'] = os.path.join(project_root, config['output']['output_dir'])
    
    # æ£€æŸ¥é¢„è®­ç»ƒæ¨¡å‹è·¯å¾„
    pretrained_path = config['model']['pretrained_encoder_path']
    if pretrained_path and not os.path.isabs(pretrained_path):
        pretrained_full_path = os.path.join(project_root, pretrained_path)
        if os.path.exists(pretrained_full_path):
            config['model']['pretrained_encoder_path'] = pretrained_full_path
            print(f"âœ… é¢„è®­ç»ƒæ¨¡å‹è·¯å¾„: {pretrained_full_path}")
        else:
            print(f"âš ï¸  é¢„è®­ç»ƒæ¨¡å‹ä¸å­˜åœ¨ï¼Œå°†ä½¿ç”¨éšæœºåˆå§‹åŒ–: {pretrained_full_path}")
            config['model']['pretrained_encoder_path'] = None
    
    if os.path.exists(data_path):
        print(f"âœ… æ•°æ®è·¯å¾„å­˜åœ¨: {data_path}")
        main(config)
    else:
        print(f"âŒ æ•°æ®è·¯å¾„ä¸å­˜åœ¨: {data_path}")